\chapter{Diskussion}
\label{cha:diskussion}
Im abschließenden Kapitel werden die Ergebnisse der Projektarbeit analysiert und diskutiert. Hierbei werden beide Modis in je einem Abschnitt berücksichtigt.

\section{Offline-Modus}
Im Offline-Modus werden gute Erkennungsraten mit bis zu 80 \% auf Einzelframes erzielt. Dies führt dazu, dass schon nach wenigen 32ms-Fenstern ein Sprecher sicher identifiziert werden kann. Allerdings kann hier kein fester Wert genannt werden, da es vom Sprecher und den Sprechpausen abhängt. Sollte die Erkennung beispielsweise in einer Sprechpause eingesetzt werden, würde diese durch das hohe Energielevel ausgeschnitten und es fände keine Identifizierung eines Sprechers statt.

Bei den Preprocessing-Algorithmen lässt MFCC LPC deutlich hinter sich. So erzielen die Kombinationen mit MFCC zwischen 26 und 31 Prozentpunkte mehr als die Kombinationen mit LPC.

Bei den Trainings-Algorithmen ist SVM mit einem linearen Kernel geringfügig besser als Neural Gas. Wobei dies beim Einsatz von LPC noch einen Unterschied von 6 Prozentpunkten ausmacht, ist es bei MFCC nur noch ein Prozentpunkt. Nach der Optimierung durch den Evolutionären Algorithmus hat sich dieser Vorsprung allerdings ins negative verkehrt. Der Einsatz vom RBF-Kernel bei SVM verzeichnet nochmal einen deutlich Sprung gegenüber den zwei anderen Trainings-Methoden. So ist SVM mit dem RBF-Kernel die Trainingsmethode mit der höchsten Erkennungsrate auf Einzelframes. In Kombination mit MFCC erzielt SVM (RBF-Kernel) somit die beste Erkennungsrate, die in dieser Projektarbeit erreicht werden konnte.

Abgesehen von der Erkennungsrate spielen in der Praxis auch weitere Faktoren eine Rolle. Sollte Skalierbarkeit wichtig sein, zum Beispiel beim Einsatz auf einer Internetplattform, so scheint die Kombination MFCC und Neural Gas am geeignetesten zu sein. Denn beim Training von SVM wird mit allen Daten trainiert. Dies führt dazu, dass bei einer stetig wachsenden Sprecheranzahl ständig neu und mit größeren Datensätzen trainiert werden muss. Bei Neural Gas dagegen kann für einen neu hinzugekommenen Sprecher einfach ein neues Codebuch erzeugt werden und zu den restlichen Codebüchern hinzugefügt werden. Allerdings wurde in dieser Projektarbeit nicht überprüft wie sich das System mit einer großen Anzahl an Sprechern verhält.

\section{Online-Modus}
Im Online-Modus konnten nur schlechte bis mittelmäßige Erkennungsraten erzeugt werden. Diese sind zu unzuverlässig, um damit arbeiten zu können. Folgende Probleme bestehen bei der Online-Erkennung:
\begin{description}
	\item[Umwelt- und Mikrofonunterschiede] Jedes Mikrofon hat seine eigene Charistika und erzeugt somit unterschiedliche Aufnahmen. Ebenso sind Hintergrundgeräusche und akustische Störungen wie Hall nicht zu vermeiden. Somit entsteht eine Diskrepanz zwischen den Trainings- und Prediction-Phase, die zu einer schlechten Erkennungrate führen kann.
	\item[Geringe Trainingsmenge] Für den Vergleich mit einem Laptopmikrofon wurden nur geringe Trainingsmengen aufgenommen. Diese sind wohl zu gering, um die Sprecher korrekt voneinander zu unterscheiden.
	\item[Fehlende Skalierung] Die Eingangsdaten wurden nicht skaliert. Da unterschiedliche Mikrophone und unterschiedliche Sitzpositionen vor dem Mikrofon zu unterschiedlichen Lautstärken führen, wäre dies allerdings notwendig gewesen um stabilere Ergebnisse zu erzielen.
	\item[Fehlendes Energielevel] Ebenso scheint das fehlende Energielevel ein gewichtiger Grund, dass keine guten Erkennungsraten erzielt wurden. So wurde in den Offline-Tests nachgewiesen, dass ein hohes Energielevel auch hohe Erkennungsraten zur Folge haben.
\end{description}
